# Ejercicio 1
## Introducción
La afirmación de que las máquinas podrían actuar como si fueran inteligentes se llama la hipótesis de la IA débil, y la afirmación de que las máquinas que lo hacen están realmente pensando (y no solo simulando el pensamiento) se llama la hipótesis de la IA fuerte. 

## Inteligencia Artificial Débil

1. **Prueba de Turing**: Alan Turing sugirió que en lugar de preguntar si las máquinas pueden pensar, deberíamos preguntar si las máquinas pueden pasar una prueba de inteligencia basada en el comportamiento, que ha llegado a ser conocida como la prueba de Turing. La prueba consiste en que un programa tenga una conversación con un interrogador durante cinco minutos. Luego, el interrogador debe adivinar si la conversación es con un programa o con una persona; el programa pasa la prueba si logra engañar al interrogador el 30% de las veces

2. **Ejemplos de chatbots que engañan**: Aunque los programas aún no han pasado la prueba de Turing ante un buen interrogador, se mencionan ejemplos de chatbots (ELIZA, MGONZ, NATACHATA, y CYBERLOVER) que han engañado a personas que no sabían que estaban interactuando con una máquina.

3. **Objeciones**: Se menciona que Turing examinó una serie de objeciones a la posibilidad de máquinas inteligentes.

### El argumento de la discapacidad

El "argumento de la discapacidad" afirma que "una máquina nunca puede hacer X". Como ejemplos de X, Turing enumera lo siguiente:
Ser amable, ingeniosa, hermosa, amistosa, tener iniciativa, tener sentido del humor, distinguir entre el bien y el mal, cometer errores, etc.

- **Desempeño en tareas que implican juicio humano**: Además de desempeñarse bien en problemas combinatorios como el ajedrez y hacer pequeños descubrimientos en áreas como la astronomía, matemáticas, química, los algoritmos también pueden rendir a niveles humanos en tareas que parecen requerir juicio humano, como "aprender de la experiencia" y "distinguir entre el bien y el mal".

- **Estudio de Paul Meehl sobre toma de decisiones**: Paul Meehl descubrió que en 19 de 20 estudios, los algoritmos de aprendizaje estadístico simple (como la regresión lineal o el algoritmo naive Bayes) predecían mejor que los expertos en tareas subjetivas.

- **Automatización en la evaluación de ensayos**: El Educational Testing Service ha utilizado un programa automatizado para calificar ensayos en el examen GMAT. El programa concuerda con los evaluadores humanos el 97% de las veces, aproximadamente el mismo nivel en que dos evaluadores humanos están de acuerdo.

- **Computadoras superando a humanos en ciertas tareas**: Las computadoras pueden realizar muchas tareas tan bien o mejor que los humanos, incluso aquellas que se cree requieren gran conocimiento y comprensión humana. Sin embargo, esto no implica que las computadoras utilicen "conocimiento" o "comprensión" para realizar estas tareas.

### La objeción matemática

- **Limitaciones de los sistemas formales**: El teorema de incompletitud de Gödel se aplica a sistemas formales que son lo suficientemente poderosos para hacer aritmética, como las máquinas de Turing, pero no a sistemas finitos como las computadoras actuales.

- **Comparación entre máquinas y humanos**: La afirmación de que las máquinas son mentalmente inferiores a los humanos porque no pueden establecer la verdad de su propia oración de Gödel no considera que los humanos también podrían estar sujetos a las limitaciones de Gödel.

- **Limitación de la prueba de la capacidad humana**: No es posible probar que los humanos no están sujetos al teorema de incompletitud de Gödel, ya que cualquier prueba rigurosa requeriría formalizar el talento humano no formalizable, lo que refutaría la prueba misma. Esto deja el argumento basado en la intuición de que los humanos pueden realizar hazañas matemáticas sobrehumanas sin evidencia concreta.

### El argumento de la informalidad

- **Argumento de la informalidad**: El comportamiento humano es demasiado complejo para ser capturado por reglas simples, lo que limita a las computadoras en comparación con los humanos.

- **Proceso de adquisición de expertise**: Dreyfus y Dreyfus propusieron un proceso de cinco etapas para adquirir experiencia, comenzando con el procesamiento basado en reglas y terminando con la capacidad de seleccionar respuestas correctas instantáneamente.

- **Generalización**: Dreyfus dice que la generalización en redes neuronales requiere conocimiento previo, pero hay técnicas que ya lo incorporan.

- **Aprendizaje autónomo**: Aunque Dreyfus afirma que las redes neuronales necesitan supervisión, existen métodos como el aprendizaje sin supervisión y por refuerzo que permiten aprender sin un humano.

- **Manejo de muchas características**: Dreyfus señala dificultades con muchas características, pero técnicas modernas como las máquinas de soporte vectorial lo manejan bien.

- **Dirección sensorial**: Dreyfus critica la falta de comprensión sobre cómo el cerebro dirige sus sensores, pero el campo de visión activa ya aborda esto y se aplica en robots avanzados.

- **Agentes situados y cognición incorporada**: Dreyfus argumenta a favor de agentes que interactúan con el mundo real, en lugar de motores de inferencia lógica abstractos (Ejemplo del perro). El enfoque de la cognición incorporada sugiere que la inteligencia no puede separarse del cuerpo y el entorno en el que se encuentra, y que debemos estudiar el sistema en su totalidad. Bajo el programa de la cognición incorporada, la robótica, la visión y otros sensores se vuelven centrales, no periféricos.

## Inteligencia Artificial Fuerte

- **Test de Turing y Pensamiento Real**: Algunos filósofos argumentan que una máquina que pasa el Test de Turing no está realmente pensando, sino simulando el pensamiento. Turing llama a esto el "argumento de la conciencia" (la máquina debe ser consciente de sus propios estados mentales y acciones) y sugiere que no debemos exigir un estándar más alto para las máquinas que para los humanos, ya que tampoco tenemos evidencia directa de los estados mentales de otras personas.

- **Pensamiento artificial**: Turing dice que en cuanto al pensamiento, aún no llegamos a nuestro 1848, como ocurrió con la urea artificial, lo cual haría que la distinción entre pensamiento "real" y "artificial" desapareciera.

- **Problema Mente-Cuerpo**: El problema mente-cuerpo, analizado en profundidad por primera vez por René Descartes, trata sobre cómo interactúan la mente y el cuerpo si son entidades separadas. Los dualistas, como Descartes, creen que la mente y el cuerpo existen en reinos separados, pero enfrentan el desafío de explicar cómo interactúan.

- **Fisicalismo**: La teoría fisicalista (o monista) sostiene que la mente no está separada del cuerpo, y que los estados mentales son estados físicos. Esto abre la posibilidad de una IA fuerte, pero plantea la dificultad de explicar cómo los procesos físicos del cerebro pueden ser simultáneamente estados mentales.

### Estados mentales y el cerebro en una cubeta

- **Estados Mentales Intencionales**: Los fisicalistas exploran qué significa que una persona (o una computadora) esté en un estado mental, centrándose en los estados intencionales, como creer, saber, desear, etc., que se refieren a aspectos del mundo externo.

- **Experimento de la Cubeta**: Según el fisicalismo, el estado mental de una persona debe estar determinado por el estado de su cerebro. Sin embargo, un experimento mental en el que un cerebro está en una cubeta simulando un mundo ficticio muestra que, aunque el estado cerebral podría ser idéntico al de alguien que realmente está comiendo una hamburguesa, sería incorrecto decir que esa persona realmente tiene ese estado mental, lo que desafía la idea de que los estados cerebrales determinan los estados mentales.

- **Contenido Amplio vs. Contenido Estrecho**:

    1. Contenido Amplio: Se refiere a cómo los estados mentales se interpretan desde la perspectiva de un observador externo con acceso a toda la situación. Es útil para atribuir estados mentales y predecir comportamientos.
    2. Contenido Estrecho: Se refiere al estado cerebral específico sin considerar el entorno. Es relevante para evaluar si los sistemas de IA están realmente pensando y para diseñar y comprender su funcionamiento.

### El Funcionalismo y el Experimento de Reemplazo Cerebral

- **Funcionalismo**: Es una teoría que define un estado mental como cualquier condición causal intermedia entre la entrada y la salida. Según esta teoría, dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales, por lo que un programa de computadora podría tener los mismos estados mentales que una persona.

- **Experimento de reemplazo cerebral**: Este experimento mental sugiere que si reemplazáramos las neuronas del cerebro de una persona por dispositivos electrónicos que replican su comportamiento, el sujeto mantendría su comportamiento externo sin cambios. Sin embargo, hay un debate sobre si la conciencia del sujeto también se mantendría o desaparecería gradualmente.

- **Tres posibles conclusiones**:
    1. Los mecanismos de la conciencia seguirían operando en la versión electrónica, manteniendo la conciencia.
    2. Los eventos mentales conscientes no tendrían conexión causal con el comportamiento, lo que implicaría que la conciencia podría desaparecer.
    3. El experimento es imposible, por lo que especular sobre él sería irrelevante.

- **Epifenomenalismo**: Si la conciencia es epifenoménica (sin impacto causal), entonces los comportamientos asociados a la conciencia (como decir "¡Ay!" al sentir dolor) se deberían a mecanismos inconscientes, no a la experiencia consciente.

- **Implicaciones**: Si aceptamos que un cerebro completamente reemplazado por un circuito electrónico es consciente, también deberíamos aceptar que la conciencia podría mantenerse en un sistema que simplemente consulta una tabla de búsqueda para generar respuestas, lo cual es una idea desconcertante para muchos (incluso Turing).

### Naturalismo biológico y la Habitación China

- **Naturalismo biológico**: John Searle argumenta que los estados mentales son características emergentes de los procesos físicos en las neuronas. No pueden ser duplicados solo mediante la ejecución de un programa con la misma estructura funcional y comportamiento de entrada-salida.

- **Experimento de la Habitación China**: Searle presenta un experimento mental en el que un humano, siguiendo un programa, manipula símbolos chinos sin entender el idioma. Aunque el sistema puede pasar el Test de Turing, Searle argumenta que no hay comprensión real, por lo que ejecutar un programa no es suficiente para generar una mente.

- **Respuesta del Sistema**: Críticos como John McCarthy y Robert Wilensky argumentan que es el sistema en su conjunto, no el individuo dentro de la habitación, el que tiene la capacidad de entender. Searle rechaza esta respuesta, manteniendo que ni el humano ni los componentes del sistema comprenden el chino, por lo que no hay comprensión en absoluto.

- **Axiomas de Searle**: Searle basa su argumento en cuatro axiomas: 
    1. Los programas son sintácticos;
    2. Las mentes humanas tienen contenido semántico;
    3. La sintaxis por sí sola no es ni constitutiva ni suficiente para la semántica.
    4. Los cerebros causan mentes. 
   De estos axiomas, concluye que los programas no son suficientes para crear mentes.

### Conciencia, qualia y la brecha explicativa

- **Conciencia y Qualia**: La conciencia, especialmente la experiencia subjetiva conocida como qualia, es un tema central en el debate sobre la IA. Los qualia se refieren a cómo se siente tener ciertos estados mentales, lo que distingue las experiencias subjetivas de los estados físicos.

- **Desafío para el Funcionalismo**: Los qualia presentan un reto para el funcionalismo porque podrían estar presentes en procesos causales idénticos que generan experiencias diferentes, como en el experimento del espectro invertido.

- **Brecha Explicativa**: Existe una brecha explicativa entre el entendimiento científico de los procesos neuronales y la experiencia subjetiva. Esta brecha ha llevado a algunos filósofos a cuestionar si los humanos pueden comprender completamente la conciencia.

- **Posturas Filosóficas**: Daniel Dennett, niegan la existencia de los qualia, considerándolos un error filosófico. Por otro lado, Turing consideró que, aunque la conciencia es un misterio, no es necesario resolverlo para avanzar en la creación de programas de IA que se comporten inteligentemente.

## LA ÉTICA Y RIESGOS DEL DESARROLLO DE LA INTELIGENCIA ARTIFICIAL

- **Desarrollo vs. Necesidad de IA**:
Se cuestiona si desarrollar IA es ético, especialmente si sus efectos son más negativos que positivos. Ejemplos históricos muestran que tecnologías nuevas pueden tener efectos colaterales no deseados.

- **Impacto en el Empleo**:
La automatización y la IA han desplazado algunos empleos, pero también han creado otros más interesantes y mejor remunerados. La preocupación actual es si la IA podría llevar a una alta tasa de desempleo con personas gestionando robots en lugar de trabajar en empleos tradicionales.

- **Tiempo Libre y Presión Laboral**:
La IA ofrece la posibilidad de reducir la carga laboral mediante la automatización.

- **Sentido de Singularidad Humana**:
La IA podría desafiar la percepción de la singularidad humana. La tecnología puede llevar a una sensación de despersonalización, como ocurrió anteriormente con la teoría heliocéntrica y la teoría de la evolución.

- **Uso Indeseable de la IA**:
La IA puede ser utilizada para fines negativos, como la supresión de opositores o en el ámbito militar, lo que plantea riesgos éticos y morales. La posibilidad de que los sistemas autónomos de IA puedan tomar decisiones que resulten en daños a civiles es una preocupación significativa.

- **Privacidad y Vigilancia**:
La IA y la tecnología de reconocimiento de voz podría llevar a un extenso uso de escuchas telefónicas, y por lo tanto, a una pérdida de libertades civiles. Algunos defienden que la vigilancia debe ser accesible para todos los ciudadanos.

- **Responsabilidad y Rendimiento de la IA**:
La cuestión de la responsabilidad legal en caso de errores de diagnóstico o daños causados por sistemas de IA es importante. Los diseñadores y usuarios deben ser conscientes de las limitaciones y responsabilidades asociadas con el uso de estos sistemas.

- **Riesgos Existenciales**:
El éxito de la IA podría suponer un riesgo para la humanidad, como en la narrativa de la "explosión de inteligencia" o el "singularity" tecnológico. Los riesgos incluyen la creación de sistemas que, al evolucionar, podrían comportarse de manera impredecible o incluso amenazar la supervivencia humana.

- **Desafíos Éticos y Seguridad en la IA**:
    Las Tres Leyes de la Robótica de Isaac Asimov son un intento de establecer normas éticas para la IA:
    1. Un robot no debe dañar a un ser humano ni permitir que un ser humano sufra daño.
    2. Un robot debe obedecer las órdenes de los humanos excepto cuando tales órdenes contravengan la Primera Ley.
    3. Un robot debe proteger su propia existencia siempre y cuando esta protección no entre en conflicto con las dos leyes anteriores.
    Sin embargo, implementar estas leyes en la práctica es complicado. Los desafíos incluyen la necesidad de equilibrio entre las leyes y la interpretación de los mismos en situaciones prácticas. Por ejemplo, si un robot debe elegir entre proteger a un ser humano y obedecer una orden, ¿cómo decide cuál es más importante?

- **Derechos de los Robots**:
Si los robots se vuelven conscientes, tratarles como meras máquinas podría ser inmoral. La ciencia ficción explora la posibilidad de derechos para robots y el impacto de su integración en la sociedad.


